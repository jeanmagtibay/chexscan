{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3a9ab4",
   "metadata": {},
   "source": [
    "# CheXScan Ensemble Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859fa16",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9901c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import datasets, layers, models\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Adam as LegacyAdam\n",
    "from keras.layers import Input, Average\n",
    "from keras.applications import DenseNet121, InceptionV3, ResNet50, VGG16\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86bc10c",
   "metadata": {},
   "source": [
    "## GPU Utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1298f0b",
   "metadata": {},
   "source": [
    "checks for available physical devices using TensorFlow's configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices()\n",
    "\n",
    "print(\"Available physical devices:\")\n",
    "for device in physical_devices:\n",
    "    print(device)\n",
    "\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(\"GPU is available\")\n",
    "    for gpu in gpu_devices:\n",
    "        print(\"GPU device name:\", gpu.name)\n",
    "else:\n",
    "    print(\"GPU is NOT available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of available physical GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# Check if there are GPUs available\n",
    "if gpus:\n",
    "    # Set memory growth for each GPU\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth set for GPU:\", gpu)\n",
    "else:\n",
    "    print(\"No GPUs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e6526",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = (224, 224)\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "CLASSES = ['normal', 'pneumonia', 'tuberculosis']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0feb618",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_transform = tf.keras.Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "data_augmentation_transform = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomWidth(0.2),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e481d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7678eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'E:/chexscan/data/train_data/',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'E:/chexscan/data/test_data/',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c78f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):  # Taking one batch\n",
    "    for i in range(9):  # Displaying 9 images\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(CLASSES[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd761b1",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = 'sparse_categorical_crossentropy'\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "num_epochs = EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b234ab77",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8cd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, valid_dataset):\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for images, labels in valid_dataset:\n",
    "        preds = model.predict(images)\n",
    "        predictions.extend(np.argmax(preds, axis=1))\n",
    "        true_labels.extend(labels.numpy())\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf63b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_metrics(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452bdd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_labels, predicted_labels, class_names):\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0122993",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834deba0",
   "metadata": {},
   "source": [
    "defines the model architecture with convolutional and max-pooling layers, followed by fully connected layers and dropout regularization. \n",
    "\n",
    "compiled with a customized Adam optimizer and specified loss function. Training includes early stopping based on validation accuracy\n",
    "\n",
    "after training, the model's performance is evaluated on a validation dataset, and metrics such as accuracy and classification report are computed.\n",
    "\n",
    "visualizations, including training history and confusion matrix, are generated to assess the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a233c8b",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_model = models.Sequential([\n",
    "    layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=INPUT_SHAPE),\n",
    "    layers.MaxPooling2D((3, 3), strides=(2, 2)),\n",
    "    layers.Conv2D(256, (5, 5), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((3, 3), strides=(2, 2)),\n",
    "    layers.Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "    layers.Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((3, 3), strides=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = LegacyAdam(learning_rate=0.0001)\n",
    "\n",
    "alexnet_model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
    "\n",
    "history_alexnet = alexnet_model.fit(train_dataset.map(lambda x, y: (data_augmentation_transform(x), y)),\n",
    "                                    validation_data=valid_dataset,\n",
    "                                    epochs=num_epochs,\n",
    "                                    callbacks=[early_stopping])\n",
    "\n",
    "true_labels_alexnet, predicted_labels_alexnet = evaluate_model(alexnet_model, valid_dataset)\n",
    "accuracy_alexnet = accuracy_score(true_labels_alexnet, predicted_labels_alexnet)\n",
    "print(\"AlexNet Accuracy:\", accuracy_alexnet)\n",
    "\n",
    "plot_history_metrics(history_alexnet)\n",
    "\n",
    "plot_confusion_matrix(true_labels_alexnet, predicted_labels_alexnet, CLASSES)\n",
    "\n",
    "print(\"Classification Report for AlexNet:\")\n",
    "print(classification_report(true_labels_alexnet, predicted_labels_alexnet, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3d092",
   "metadata": {},
   "source": [
    "## DenseNet-121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe372975",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model = DenseNet121(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "\n",
    "densenet_top = tf.keras.Sequential([\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "densenet_model = tf.keras.Model(inputs=densenet_model.input, outputs=densenet_top(densenet_model.output))\n",
    "\n",
    "optimizer = LegacyAdam(learning_rate=0.0001)\n",
    "\n",
    "densenet_model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
    "\n",
    "history_densenet = densenet_model.fit(train_dataset.map(lambda x, y: (data_augmentation_transform(x), y)), validation_data=valid_dataset, epochs=num_epochs, callbacks=[early_stopping])\n",
    "\n",
    "true_labels_densenet, predicted_labels_densenet = evaluate_model(densenet_model, valid_dataset)\n",
    "accuracy_densenet = accuracy_score(true_labels_densenet, predicted_labels_densenet)\n",
    "print(\"DenseNet121 Accuracy:\", accuracy_densenet)\n",
    "\n",
    "plot_history_metrics(history_densenet)\n",
    "\n",
    "plot_confusion_matrix(true_labels_densenet, predicted_labels_densenet, CLASSES)\n",
    "\n",
    "print(\"Classification Report for DenseNet121:\")\n",
    "print(classification_report(true_labels_densenet, predicted_labels_densenet, target_names=CLASSES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d7fb5",
   "metadata": {},
   "source": [
    "## ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24285ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "\n",
    "resnet_top = tf.keras.Sequential([\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "resnet_model = tf.keras.Model(inputs=resnet_model.input, outputs=resnet_top(resnet_model.output))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
    "\n",
    "resnet_model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "history_resnet = resnet_model.fit(train_dataset.map(lambda x, y: (data_augmentation_transform(x), y)),\n",
    "                                  validation_data=valid_dataset,\n",
    "                                  epochs=num_epochs,\n",
    "                                  callbacks=[early_stopping])\n",
    "\n",
    "true_labels_resnet, predicted_labels_resnet = evaluate_model(resnet_model, valid_dataset)\n",
    "accuracy_resnet = accuracy_score(true_labels_resnet, predicted_labels_resnet)\n",
    "print(\"ResNet50 Accuracy:\", accuracy_resnet)\n",
    "\n",
    "plot_history_metrics(history_resnet)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(true_labels_resnet, predicted_labels_resnet, CLASSES)\n",
    "\n",
    "print(\"Classification Report for ResNet50:\")\n",
    "print(classification_report(true_labels_resnet, predicted_labels_resnet, target_names=CLASSES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a4be2",
   "metadata": {},
   "source": [
    "## VGG-16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb34a18",
   "metadata": {},
   "source": [
    "setting up an early stopping callback during model training to prevent overfitting and to stop training when the model performance stops improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "\n",
    "vgg_top = tf.keras.Sequential([\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "vgg_model = tf.keras.Model(inputs=vgg_model.input, outputs=vgg_top(vgg_model.output))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
    "\n",
    "vgg_model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "history_vgg = vgg_model.fit(train_dataset.map(lambda x, y: (data_augmentation_transform(x), y)), validation_data=valid_dataset, epochs=num_epochs, callbacks=[early_stopping])\n",
    "\n",
    "true_labels_vgg, predicted_labels_vgg = evaluate_model(vgg_model, valid_dataset)\n",
    "accuracy_vgg = accuracy_score(true_labels_vgg, predicted_labels_vgg)\n",
    "print(\"VGG16 Accuracy:\", accuracy_vgg)\n",
    "\n",
    "plot_history_metrics(history_vgg)\n",
    "\n",
    "plot_confusion_matrix(true_labels_vgg, predicted_labels_vgg, CLASSES)\n",
    "\n",
    "print(\"Classification Report for VGG16:\")\n",
    "print(classification_report(true_labels_vgg, predicted_labels_vgg, target_names=CLASSES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0634e1c0",
   "metadata": {},
   "source": [
    "## Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "\n",
    "inception_top = tf.keras.Sequential([\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "inception_model = tf.keras.Model(inputs=inception_model.input, outputs=inception_top(inception_model.output))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
    "\n",
    "inception_model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "history_inception = inception_model.fit(train_dataset.map(lambda x, y: (data_augmentation_transform(x), y)), validation_data=valid_dataset, epochs=num_epochs, callbacks=[early_stopping])\n",
    "\n",
    "true_labels_inception, predicted_labels_inception = evaluate_model(inception_model, valid_dataset)\n",
    "accuracy_inception = accuracy_score(true_labels_inception, predicted_labels_inception)\n",
    "print(\"InceptionV3 Accuracy:\", accuracy_inception)\n",
    "\n",
    "plot_history_metrics(history_inception)\n",
    "\n",
    "plot_confusion_matrix(true_labels_inception, predicted_labels_inception, CLASSES)\n",
    "\n",
    "print(\"Classification Report for InceptionV3:\")\n",
    "print(classification_report(true_labels_inception, predicted_labels_inception, target_names=CLASSES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4925d940",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c06f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy_alexnet_percent = accuracy_alexnet * 100\n",
    "accuracy_densenet_percent = accuracy_densenet * 100\n",
    "accuracy_inception_percent = accuracy_inception * 100\n",
    "accuracy_resnet_percent = accuracy_resnet * 100\n",
    "accuracy_vgg_percent = accuracy_vgg * 100\n",
    "\n",
    "print(f\"AlexNet Accuracy: {accuracy_alexnet_percent:.2f}%\")\n",
    "print(f\"DenseNet121 Accuracy: {accuracy_densenet_percent:.2f}%\")\n",
    "print(f\"InceptionV3 Accuracy: {accuracy_inception_percent:.2f}%\")\n",
    "print(f\"ResNet50 Accuracy: {accuracy_resnet_percent:.2f}%\")\n",
    "print(f\"VGG16 Accuracy: {accuracy_vgg_percent:.2f}%\")\n",
    "\n",
    "models = ['AlexNet', 'DenseNet121', 'InceptionV3', 'ResNet50', 'VGG16']\n",
    "accuracies = [accuracy_alexnet_percent, accuracy_densenet_percent, accuracy_inception_percent, accuracy_resnet_percent, accuracy_vgg_percent]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, accuracies, color='skyblue')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy of Different Models')\n",
    "plt.ylim(0, 100)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b1293",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trained models in a list\n",
    "# top_models = [alexnet_model, densenet_model, inception_model, resnet_model, vgg_model]\n",
    "top_models = [densenet_model, inception_model, resnet_model]\n",
    "\n",
    "# Define the names of the models\n",
    "model_names = [\"DenseNet121\", \"InceptionV3\", \"ResNet50\"]\n",
    "\n",
    "# Evaluate models and store their accuracies along with their names\n",
    "model_accuracies = []\n",
    "for model, name in zip(top_models, model_names):\n",
    "    accuracy = model.evaluate(valid_dataset)[1]\n",
    "    model_accuracies.append((name, model, accuracy))  # Store the model along with its name and accuracy\n",
    "\n",
    "# Sort the models based on accuracy in descending order\n",
    "sorted_models = sorted(model_accuracies, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Select the top 3 models\n",
    "top3_models = sorted_models[:3]\n",
    "# t3models = []\n",
    "# Display the top 3 models along with their accuracies\n",
    "for i, (name, model, accuracy) in enumerate(top3_models, start=1):\n",
    "    print(f\"Top {i} Model: {name}, Accuracy: {accuracy:.4f}\")\n",
    "    # t3models[i] = model\n",
    "\n",
    "# Store the top 3 models in a list\n",
    "top3_model_names = [name for name, _, _ in top3_models]\n",
    "top3_models = [model for _, model, _ in top3_models]\n",
    "print(top3_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a440c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(image, t3models):\n",
    "    predictions = [model.predict(np.expand_dims(image, axis=0)) for model in t3models]\n",
    "    return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e0956",
   "metadata": {},
   "source": [
    "## Saving the Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the image\n",
    "image_path = \"E:/chexscan/exp/test/normal.png\"\n",
    "image = cv2.imread(image_path)\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "image = cv2.resize(image, (224, 224))  # Resize to the required input size\n",
    "\n",
    "# Convert image to NumPy array if it's not already and cast it to float32\n",
    "image = np.array(image, dtype=np.float32)\n",
    "\n",
    "# Normalize the pixel values\n",
    "image /= 255.0\n",
    "\n",
    "# Get ensemble predictions for the image\n",
    "ensemble_predictions = ensemble_predict(image, top3_models)\n",
    "\n",
    "# Display the ensemble predictions for the image\n",
    "for class_index, class_name in enumerate(CLASSES):\n",
    "    print(f\"Ensemble Prediction for class '{class_name}': {ensemble_predictions[0][class_index]:.2f}\")\n",
    "\n",
    "print(\"ensemble predictions: \", ensemble_predictions)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_class_indices = np.argmax(ensemble_predictions, axis=1)\n",
    "predicted_class_names = [CLASSES[i] for i in predicted_class_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d82fa2",
   "metadata": {},
   "source": [
    "<!-- # Make predictions using the ensemble model\n",
    "predictions = ensemble_model.predict(input_image)\n",
    "\n",
    "# Extract class names and corresponding probabilities\n",
    "class_names = [\"normal\", \"pneumonia\", \"tuberculosis\"]  # Replace with your actual class names\n",
    "probabilities = predictions[0]\n",
    "\n",
    "# Sort the probabilities in descending order\n",
    "sorted_indices = np.argsort(probabilities)[::-1]\n",
    "\n",
    "# Display the top predicted class and its confidence\n",
    "top_class = class_names[sorted_indices[0]]\n",
    "top_confidence = probabilities[sorted_indices[0]]\n",
    "print(f\"Top predicted class: {top_class}, Confidence: {top_confidence:.2f}\")\n",
    "\n",
    "# Display the next two predicted classes and their confidences\n",
    "for i in range(1, 3):\n",
    "    class_name = class_names[sorted_indices[i]]\n",
    "    confidence = probabilities[sorted_indices[i]]\n",
    "    print(f\"Predicted class {i+1}: {class_name}, Confidence: {confidence:.2f}\") -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape based on your models\n",
    "input_shape = (224, 224, 3)  # Ex|ample input shape for RGB images of size 299x299\n",
    "\n",
    "# Define inputs for the ensemble model\n",
    "ensemble_inputs = [Input(shape=input_shape) for _ in range(len(top3_models))]\n",
    "\n",
    "# Get outputs of the top 3 models\n",
    "model_outputs = [model(inputs) for model, inputs in zip(top3_models, ensemble_inputs)]\n",
    "\n",
    "# Average the outputs\n",
    "ensemble_output = Average()(model_outputs)\n",
    "\n",
    "# Create the ensemble model\n",
    "ensemble_model = Model(inputs=ensemble_inputs, outputs=ensemble_output)\n",
    "\n",
    "# Compile the ensemble model (if needed)\n",
    "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ensemble_model_04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dae531",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model.save('ensemble_model_05.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_model.save('alexnet_model.keras')\n",
    "densenet_model.save('densenet_model.keras')\n",
    "inception_model.save('inception_model.keras')\n",
    "resnet_model.save('resnet_model.keras')\n",
    "vgg_model.save('vgg_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb592718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
